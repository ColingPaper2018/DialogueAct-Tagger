{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>DialogueAct Tagger</h1>\n",
    "\n",
    "<h3>Abstract</h3>\n",
    "This notebook provides an overview of the main features of the DialogueAct Tagger repository, including instructions on how to configure, train and test the Dialogue Act tagger on the various provided corpora. This project is currently under development and still contains various bugs and missing features. You're more than welcome to add any ideas or issues in the \"Issues\" section of the repo, or to contact anyone listed under the \"Contacts\" section for help and support. If you use this work, remember to cite \n",
    "\n",
    "<i>Mezza, Stefano, et al. \"ISO-Standard Domain-Independent Dialogue Act Tagging for Conversational Agents.\" Proceedings of the 27th International Conference on Computational Linguistics. 2018.</i>\n",
    "\n",
    "<h3> 1. Getting started </h3>\n",
    "This notebook requires Python 3.5+ to work correctly.\n",
    "\n",
    "After cloning the repository, please launch the <code>install.sh</code> script, which will install all the necessary python dependencies and download all the publicly-available corpora, placing them in their default directories. \n",
    "\n",
    "<h3> 2. Training an SVM Dialogue Act Tagger </h3>\n",
    "\n",
    "We will begin by training a Dialogue Act Tagger based on Support Vector Machines and Scikit learn classifiers. The first thing to do is to create an SVM Config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import SVMConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM Config takes the following parameters, which you can change in the code below to obtain different Dialogue Act Taggers:\n",
    "\n",
    "<ul>\n",
    "    <li><b>taxonomy:</b> this is the taxonomy (i.e. set of tags) that you want to use. We currently support all the default taxonomies for the provided datasets, plus the ISO Standard for Dialogue Act Tagging [1]. \n",
    "    </li>\n",
    "    <li><b>dep, indexed_dep, indexed_pos, prev, ngrams:</b> whether the SVM classifier should use any of those features in the learning and inference phases. The features are, in order: <i>Dependency tags</i>, <i>Indexed dependency tags</i> (i.e. dependency tags with the index of the corresponding token), <i>IndexedÂ Part-Of-Speech (POS) tags</i>, <i>Previous Dialogue Act label</i>, <i>Length of the n-grams for lexical features</i>\n",
    "    <li> <b>List of corpora to use for the training</b>,passed as a list of Tuples (Type of the corpus, folder containing the corpus)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpora.taxonomy import Taxonomy\n",
    "from corpora.maptask import Maptask\n",
    "from corpora.switchboard import Switchboard\n",
    "from corpora.ami import AMI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SVMConfig(taxonomy=Taxonomy.ISO, \n",
    "                   dep=True, \n",
    "                   indexed_dep=True, \n",
    "                   indexed_pos=True, \n",
    "                   prev=True, \n",
    "                   ngrams=True,\n",
    "                   corpora_list=[(Maptask, str(Path(\"data/Maptask\").resolve())),\n",
    "                                 (AMI, str(Path(\"data/AMI/corpus\").resolve())),\n",
    "                                 (Switchboard, str(Path(\"data/Switchboard\").resolve()))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a config file, we can create the SVM Trainer object, which takes just our config file as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.svm_trainer import SVMTrainer\n",
    "trainer = SVMTrainer(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainer's <code>train</code> method will train a dialogue act tagger. It will both return the tagger as an output and save it in the <code>models</code> folder, in a subfolder based on the current timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.path.dirname(trainer.config.out_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_tagger = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now finally use our DA tagger to tag an input utterance. The tagger is contextual, meaning that it will use the previous utterance as context when predicting the next one. It is possible to use the <code>Utterance</code> class as input to provide this information. Alternatively, the tagger will use the previous DA it predicted, which is stored internally by the class. We will now see an example of both these behaviours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_tagger.tag(\"Do you like chicken?\")\n",
    "da_tagger.tag(\"Yes\")\n",
    "\n",
    "da_tagger.tag(Utterance(\"yes\", [], [], 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to change the tagger type to a Transformer tagger, which uses a BERT-based neural transformer architecture. In order to do so, we will need to change our config and tagger type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taggers.transformer_tagger import TransformerTagger\n",
    "from trainers.transformer_trainer import TransformerTrainer\n",
    "from config import TransformerConfig\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformerConfig(taxonomy=Taxonomy.ISO, corpora_list=[(Maptask, str(Path(\"data/Maptask\").resolve())),\n",
    "                                 (AMI, str(Path(\"data/AMI/corpus\").resolve())),\n",
    "                                 (Switchboard, str(Path(\"data/Switchboard\").resolve()))], device='cpu', optimizer=optim.Adam,\n",
    "                                  lr=2e-5, n_epochs=5, batch_size=64, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = TransformerTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ISO_DA:Training Dialogue Act Tagger for Taxonomy.ISO taxonomy, using the following corpora:['Maptask', 'AMI', 'Switchboard']\n",
      "INFO:ISO_DA:Loading corpus Maptask\n",
      "INFO:ISO_DA:Loading corpus AMI\n",
      "INFO:ISO_DA:Loading corpus Switchboard\n",
      "INFO:ISO_DA:All corpora loaded!\n",
      "INFO:ISO_DA:Training dimension pipeline\n",
      "/Library/Python/3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Library/Python/3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "INFO:ISO_DA:Training model dimension\n",
      "INFO:ISO_DA:Finished Training dimension!\n",
      "INFO:ISO_DA:Training communication function pipeline for dimension 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ==> models/1614441554.043312/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ISO_DA:Skipping training for comm_0; dataset length was 0, n_classes=0\n",
      "INFO:ISO_DA:Training communication function pipeline for dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ==> models/1614441554.043312/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ISO_DA:Skipping training for comm_1; dataset length was 0, n_classes=0\n",
      "INFO:ISO_DA:Training communication function pipeline for dimension 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ==> models/1614441554.043312/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ISO_DA:Skipping training for comm_2; dataset length was 0, n_classes=0\n",
      "INFO:ISO_DA:Training communication function pipeline for dimension 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ==> models/1614441554.043312/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ISO_DA:Skipping training for comm_3; dataset length was 0, n_classes=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ==> models/1614441554.043312/\n"
     ]
    }
   ],
   "source": [
    "t = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tag(\"how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
