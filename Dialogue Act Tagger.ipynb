{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>DialogueAct Tagger</h1>\n",
    "\n",
    "<h3>Abstract</h3>\n",
    "This notebook provides an overview of the main features of the DialogueAct Tagger repository, including instructions on how to configure, train and test the Dialogue Act tagger on the various provided corpora. This project is currently under development and still contains various bugs and missing features. You're more than welcome to add any ideas or issues in the \"Issues\" section of the repo, or to contact anyone listed under the \"Contacts\" section for help and support. If you use this work, remember to cite \n",
    "\n",
    "<i>Mezza, Stefano, et al. \"ISO-Standard Domain-Independent Dialogue Act Tagging for Conversational Agents.\" Proceedings of the 27th International Conference on Computational Linguistics. 2018.</i>\n",
    "\n",
    "<h3> 1. Getting started </h3>\n",
    "This notebook requires Python 3.5+ to work correctly.\n",
    "\n",
    "After cloning the repository, please launch the <code>install.sh</code> script, which will install all the necessary python dependencies and download all the publicly-available corpora, placing them in their default directories. \n",
    "\n",
    "<h3> 2. Training and testing an SVM Dialogue Act Tagger </h3>\n",
    "\n",
    "<h4> 2.1. Training</h4>\n",
    "\n",
    "We will begin by training a Dialogue Act Tagger based on Support Vector Machines and Scikit learn classifiers. The first thing to do is to create an SVM Config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import SVMConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM Config takes the following parameters, which you can change in the code below to obtain different Dialogue Act Taggers:\n",
    "\n",
    "<ul>\n",
    "    <li><b>taxonomy:</b> this is the taxonomy (i.e. set of tags) that you want to use. We currently support all the default taxonomies for the provided datasets, plus the ISO Standard for Dialogue Act Tagging [1]. \n",
    "    </li>\n",
    "    <li><b>dep, indexed_dep, indexed_pos, prev, ngrams:</b> whether the SVM classifier should use any of those features in the learning and inference phases. The features are, in order: <i>Dependency tags</i>, <i>Indexed dependency tags</i> (i.e. dependency tags with the index of the corresponding token), <i>IndexedÂ Part-Of-Speech (POS) tags</i>, <i>Previous Dialogue Act label</i>, <i>Length of the n-grams for lexical features</i>\n",
    "    <li> <b>List of corpora to use for the training</b>,passed as a list of Tuples (Type of the corpus, folder containing the corpus)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpora.taxonomy import Taxonomy\n",
    "from corpora.maptask import Maptask\n",
    "from corpora.switchboard import Switchboard\n",
    "from corpora.ami import AMI\n",
    "from corpora.midas import MIDAS\n",
    "from taggers.svm_tagger import SVMTagger\n",
    "\n",
    "from corpora.corpus import Utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SVMConfig(taxonomy=Taxonomy.ISO, \n",
    "                   dep=True, \n",
    "                   indexed_dep=True, \n",
    "                   indexed_pos=True, \n",
    "                   prev=True, \n",
    "                   ngrams=True,\n",
    "                   pos=True,\n",
    "                   out_folder=\"models/svm_example/\")\n",
    "corpora_list=[(MIDAS, str(Path(\"data/MIDAS\").resolve())),\n",
    "              (Switchboard, str(Path(\"data/Switchboard\").resolve())),\n",
    "              (AMI, str(Path(\"data/AMI/corpus\").resolve())),\n",
    "              (Maptask, str(Path(\"data/Maptask\").resolve()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a config file, we can create the SVM Trainer object, which takes just our config file as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.svm_trainer import SVMTrainer\n",
    "trainer = SVMTrainer(config, corpora_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the DA distribution for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISODimension.Task: 653493\n",
      "ISOTaskFunction.Unknown: 75306\n",
      "ISOTaskFunction.Statement: 362657\n",
      "ISOTaskFunction.PropQ: 8039\n",
      "ISOTaskFunction.SetQ: 2979\n",
      "ISOTaskFunction.ChoiceQ: 221\n",
      "ISOTaskFunction.Directive: 93277\n",
      "ISOTaskFunction.Commissive: 10640\n",
      "\n",
      "ISODimension.SocialObligation: 2851\n",
      "ISOSocialFunction.Unknown: 0\n",
      "ISOSocialFunction.Thanking: 141\n",
      "ISOSocialFunction.Salutation: 2503\n",
      "ISOSocialFunction.Apology: 207\n",
      "\n",
      "ISODimension.Feedback: 45999\n",
      "ISOFeedbackFunction.Unknown: 0\n",
      "ISOFeedbackFunction.Feedback: 45999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.da_distribution_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there's a heavy inbalance in our dataset. There's over 300,000 <i>Statements</i> and only around 200 <i>ChoiceQuestions</i>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainer's <code>train</code> method will train a dialogue act tagger. It will both return the tagger as an output and save it in the <code>models</code> folder, in a subfolder based on the current timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISODimension.Task: 653493\n",
      "ISOTaskFunction.Unknown: 75306\n",
      "ISOTaskFunction.Statement: 362657\n",
      "ISOTaskFunction.PropQ: 8039\n",
      "ISOTaskFunction.SetQ: 2979\n",
      "ISOTaskFunction.ChoiceQ: 221\n",
      "ISOTaskFunction.Directive: 93277\n",
      "ISOTaskFunction.Commissive: 10640\n",
      "\n",
      "ISODimension.SocialObligation: 2851\n",
      "ISOSocialFunction.Unknown: 0\n",
      "ISOSocialFunction.Thanking: 141\n",
      "ISOSocialFunction.Salutation: 2503\n",
      "ISOSocialFunction.Apology: 207\n",
      "\n",
      "ISODimension.Feedback: 45999\n",
      "ISOFeedbackFunction.Unknown: 0\n",
      "ISOFeedbackFunction.Feedback: 45999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "da_tagger = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our DA Tagger stored in the <code>da_tagger</code> variable. It is also possible to load the tagger from the path where all the model and config files are saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_tagger = SVMTagger.from_folder(\"models/svm_example/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 2.2. Testing </h4>\n",
    "\n",
    "We can now finally use our DA tagger to tag an input utterance. The tagger is contextual, meaning that it will use the previous utterance as context when predicting the next one. It is possible to use the <code>Utterance</code> class as input to provide this information. Alternatively, the tagger will use the previous DA it predicted, which is stored internally by the class. We will now see an example of both these behaviours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(da_tagger.tag(\"do you like chicken?\"))\n",
    "print(da_tagger.tag(\"yes\"))\n",
    "\n",
    "print(da_tagger.tag(Utterance(\"can you pass me the salt?\", [], [], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tester import DialogueActTester\n",
    "corpora=[]\n",
    "for c in corpora_list:\n",
    "        corpora.append(c[0](c[1], config.taxonomy))\n",
    "tester = DialogueActTester(corpora=corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.test(da_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to change the tagger type to a Transformer tagger, which uses a BERT-based neural transformer architecture. In order to do so, we will need to change our config and tagger type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taggers.transformer_tagger import TransformerTagger\n",
    "from trainers.transformer_trainer import TransformerTrainer\n",
    "from config import TransformerConfig\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'corpora_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-92cb47f5921f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m config = TransformerConfig(taxonomy=Taxonomy.ISO, corpora_list=[(Maptask, str(Path(\"data/Maptask\").resolve())),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                  \u001b[0;34m(\u001b[0m\u001b[0mAMI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/AMI/corpus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                  (Switchboard, str(Path(\"data/Switchboard\").resolve()))], device='cpu', optimizer=optim.Adam,\n\u001b[1;32m      4\u001b[0m                                   lr=2e-5, n_epochs=5, batch_size=64, max_seq_len=128)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'corpora_list'"
     ]
    }
   ],
   "source": [
    "config = TransformerConfig(taxonomy=Taxonomy.ISO, corpora_list=[(Maptask, str(Path(\"data/Maptask\").resolve())),\n",
    "                                 (AMI, str(Path(\"data/AMI/corpus\").resolve())),\n",
    "                                 (Switchboard, str(Path(\"data/Switchboard\").resolve()))], device='cpu', optimizer=optim.Adam,\n",
    "                                  lr=2e-5, n_epochs=5, batch_size=64, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = TransformerTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tag(\"how are you\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
