{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>DialogueAct Tagger</h1>\n",
    "\n",
    "<h3>Abstract</h3>\n",
    "This notebook provides an overview of the main features of the DialogueAct Tagger repository, including instructions on how to configure, train and test the Dialogue Act tagger on the various provided corpora. This project is currently under development and still contains various bugs and missing features. You're more than welcome to add any ideas or issues in the \"Issues\" section of the repo, or to contact anyone listed under the \"Contacts\" section for help and support. If you use this work, remember to cite \n",
    "\n",
    "<i>Mezza, Stefano, et al. \"ISO-Standard Domain-Independent Dialogue Act Tagging for Conversational Agents.\" Proceedings of the 27th International Conference on Computational Linguistics. 2018.</i>\n",
    "\n",
    "<h3> 1. Getting started </h3>\n",
    "This notebook requires Python 3.5+ to work correctly.\n",
    "\n",
    "After cloning the repository, please launch the <code>install.sh</code> script, which will install all the necessary python dependencies and download all the publicly-available corpora, placing them in their default directories. \n",
    "\n",
    "<h3> 2. Training and testing an SVM Dialogue Act Tagger </h3>\n",
    "\n",
    "<h4> 2.1. Training</h4>\n",
    "\n",
    "We will begin by training a Dialogue Act Tagger based on Support Vector Machines and Scikit learn classifiers. The first thing to do is to create an SVM Config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y0/45rlmq890wq3v5qyxq6wj1r40000gn/T/ipykernel_50228/931977688.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVMConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/PhD/Code/DialogueAct-Tagger/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCalibratedClassifierCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaxonomy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTaxonomy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from config import SVMConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM Config takes the following parameters, which you can change in the code below to obtain different Dialogue Act Taggers:\n",
    "\n",
    "<ul>\n",
    "    <li><b>taxonomy:</b> this is the taxonomy (i.e. set of tags) that you want to use. We currently support all the default taxonomies for the provided datasets, plus the ISO Standard for Dialogue Act Tagging [1]. \n",
    "    </li>\n",
    "    <li><b>dep, indexed_dep, indexed_pos, prev, ngrams:</b> whether the SVM classifier should use any of those features in the learning and inference phases. The features are, in order: <i>Dependency tags</i>, <i>Indexed dependency tags</i> (i.e. dependency tags with the index of the corresponding token), <i>IndexedÂ Part-Of-Speech (POS) tags</i>, <i>Previous Dialogue Act label</i>, <i>Length of the n-grams for lexical features</i>\n",
    "    <li> <b>List of corpora to use for the training</b>,passed as a list of Tuples (Type of the corpus, folder containing the corpus)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpora.taxonomy import Taxonomy\n",
    "from corpora.maptask import Maptask\n",
    "from corpora.switchboard import Switchboard\n",
    "from corpora.ami import AMI\n",
    "from corpora.midas import MIDAS\n",
    "from corpora.daily_dialog import DailyDialog\n",
    "from taggers.svm_tagger import SVMTagger\n",
    "\n",
    "from corpora.corpus import Utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SVMConfig(taxonomy=Taxonomy.ISO, \n",
    "                   dep=True, \n",
    "                   indexed_dep=True, \n",
    "                   indexed_pos=True, \n",
    "                   prev=True, \n",
    "                   ngrams=True,\n",
    "                   pos=True,\n",
    "                   out_folder=\"models/svm_example/\")\n",
    "corpora_list=[(Switchboard, str(Path(\"data/Switchboard\").resolve())),\n",
    "              (DailyDialog, str(Path(\"data/DailyDialog\").resolve()))]\n",
    "              #(MIDAS, str(Path(\"data/MIDAS\").resolve())),\n",
    "              #(AMI, str(Path(\"data/AMI/corpus\").resolve())),\n",
    "              #(Maptask, str(Path(\"data/Maptask\").resolve()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we will be using the DailyDialog and Switchboard corpora. These two corpora provide an adequate balance of dialogue acts and are publicly available. Feel free to uncomment any of the lines in the previous block of code if you own the corresponding corpus. \n",
    "\n",
    "Now that we have a config file, we can create the SVM Trainer object, which takes just our config file as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.svm_trainer import SVMTrainer\n",
    "trainer = SVMTrainer(config, corpora_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the DA distribution for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISODimension.Task: 229801\n",
      "ISOTaskFunction.Unknown: 157411\n",
      "ISOTaskFunction.Statement: 39873\n",
      "ISOTaskFunction.PropQ: 7015\n",
      "ISOTaskFunction.SetQ: 2061\n",
      "ISOTaskFunction.ChoiceQ: 221\n",
      "ISOTaskFunction.Directive: 15020\n",
      "ISOTaskFunction.Commissive: 8200\n",
      "\n",
      "ISODimension.SocialObligation: 2748\n",
      "ISOSocialFunction.Unknown: 0\n",
      "ISOSocialFunction.Thanking: 68\n",
      "ISOSocialFunction.Salutation: 2503\n",
      "ISOSocialFunction.Apology: 177\n",
      "\n",
      "ISODimension.Feedback: 41949\n",
      "ISOFeedbackFunction.Unknown: 0\n",
      "ISOFeedbackFunction.Feedback: 41949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.da_distribution_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainer's <code>train</code> method will train a dialogue act tagger. It will both return the tagger as an output and save it in the <code>models</code> folder, in a subfolder based on the current timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ISO_DA:Training Dialogue Act Tagger for Taxonomy.ISO taxonomy, using the following corpora:['Switchboard', 'DailyDialog']\n",
      "INFO:ISO_DA:Training dimension pipeline\n",
      "INFO:ISO_DA:Tagset for this classifier: {1, 2, 3}\n",
      "INFO:ISO_DA:Training communication function pipeline for dimension 1\n",
      "INFO:ISO_DA:Tagset for this classifier: {1, 2, 3, 4, 5, 6}\n",
      "/Library/Python/3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "INFO:ISO_DA:Training communication function pipeline for dimension 2\n",
      "INFO:ISO_DA:Tagset for this classifier: {1, 2, 3}\n",
      "INFO:ISO_DA:Training communication function pipeline for dimension 3\n",
      "INFO:ISO_DA:Tagset for this classifier: {1}\n",
      "WARNING:ISO_DA:The only tag available for this classifier is 1.The classifier will still be trained, but it won't recognise any other labels.Please provide additional data to obtain a working classifier. You can check README.md for information on how to obtain more data\n"
     ]
    }
   ],
   "source": [
    "da_tagger = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our DA Tagger stored in the <code>da_tagger</code> variable. It is also possible to load the tagger from the path where all the model and config files are saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_tagger = SVMTagger.from_folder(\"models/svm_example/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 2.2. Testing </h4>\n",
    "\n",
    "We can now finally use our DA tagger to tag an input utterance. The tagger is contextual, meaning that it will use the previous utterance as context when predicting the next one. It is possible to use the <code>Utterance</code> class as input to provide this information. Alternatively, the tagger will use the previous DA it predicted, which is stored internally by the class. We will now see an example of both these behaviours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ISOTag(dimension=<ISODimension.Task: 1>, comm_function=<ISOTaskFunction.Directive: 5>)]\n",
      "[ISOTag(dimension=<ISODimension.Task: 1>, comm_function=<ISOTaskFunction.Statement: 1>)]\n",
      "[ISOTag(dimension=<ISODimension.Task: 1>, comm_function=<ISOTaskFunction.Directive: 5>)]\n"
     ]
    }
   ],
   "source": [
    "print(da_tagger.tag(\"can you swim?\"))\n",
    "print(da_tagger.tag(\"yes i can !\"))\n",
    "\n",
    "print(da_tagger.tag(Utterance(\"can you pass me the salt?\", [], [], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tester import DialogueActTester\n",
    "corpora=[]\n",
    "for c in corpora_list:\n",
    "        corpora.append(c[0](c[1], config.taxonomy))\n",
    "tester = DialogueActTester(corpora=corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.85      0.99      0.91        78\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       100\n",
      "   macro avg       0.58      0.66      0.62       100\n",
      "weighted avg       0.73      0.85      0.79       100\n",
      " samples avg       0.85      0.85      0.85       100\n",
      "\n",
      "Communication Function Report for ISODimension.Task\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.04        46\n",
      "           1       0.92      0.96      0.94        23\n",
      "           2       0.07      1.00      0.12         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           5       0.80      1.00      0.89         4\n",
      "           6       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.40        78\n",
      "   macro avg       0.63      0.58      0.44        78\n",
      "weighted avg       0.93      0.40      0.37        78\n",
      "\n",
      "Communication Function Report for ISODimension.SocialObligation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Python/3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-30950caba485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda_tagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/PhD/Code/DialogueAct-Tagger/tester.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, tagger)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                 \u001b[0my_comm_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Communication Function Report for {dimension}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_comm_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_comm_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                     \u001b[0;31m# labels=labels, target_names=target_names))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weighted avg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:>{width}s} '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' {:>9}'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "tester.test(da_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to change the tagger type to a Transformer tagger, which uses a BERT-based neural transformer architecture. In order to do so, we will need to change our config and tagger type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taggers.transformer_tagger import TransformerTagger\n",
    "from trainers.transformer_trainer import TransformerTrainer\n",
    "from config import TransformerConfig\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformerConfig(taxonomy=Taxonomy.ISO, device='cpu', optimizer=optim.Adam,\n",
    "                                  lr=2e-5, n_epochs=1, batch_size=256, max_seq_len=128,\n",
    "                                  out_folder=\"models/transformer_example/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = TransformerTrainer(config, corpora_list=[\n",
    "                                #(Maptask, str(Path(\"data/Maptask\").resolve())),\n",
    "                                #(AMI, str(Path(\"data/AMI/corpus\").resolve())),\n",
    "                                (Switchboard, str(Path(\"data/Switchboard\").resolve())),\n",
    "                                (DailyDialog, str(Path(\"data/DailyDialog\").resolve()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tag(\"how are you\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
